{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from templates import *\n",
    "\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = \"<path to data>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_eval(root: Path, lp: str):\n",
    "    # Load train_eval.input.txt and train_eval.output.txt for a lp.\n",
    "    input_path = root / lp / \"train_eval.input.txt\"\n",
    "    output_path = root / lp / \"train_eval.output.txt\"\n",
    "    inputs = input_path.read_text().split(\"\\n\")\n",
    "    outputs = output_path.read_text().split(\"\\n\")\n",
    "    assert len(inputs) == len(outputs)\n",
    "    records = []\n",
    "    for i, o in zip(inputs, outputs):\n",
    "        records.append({\"input\": i, \"output\": o, \"lp\": lp})\n",
    "\n",
    "    train_eval = pd.DataFrame.from_records(records)\n",
    "    \n",
    "    return train_eval\n",
    "\n",
    "def load_few_shot(root: Path, lp: str):\n",
    "    # Load train_eval.input.txt and train_eval.output.txt for a lp.\n",
    "    input_path = root / lp / \"few_shot.input.txt\"\n",
    "    output_path = root / lp / \"few_shot.output.txt\"\n",
    "    inputs = input_path.read_text().split(\"\\n\")\n",
    "    outputs = output_path.read_text().split(\"\\n\")\n",
    "    assert len(inputs) == len(outputs)\n",
    "    records = []\n",
    "    for i, o in zip(inputs, outputs):\n",
    "        records.append({\"input\": i, \"output\": o, \"lp\": lp})\n",
    "    \n",
    "    train_eval = pd.DataFrame.from_records(records)\n",
    "    \n",
    "    return train_eval\n",
    "\n",
    "def sample_examples(few_shot_df: pd.DataFrame, lp: str, n: int, k: int, seed: int = 42) -> List[List[Tuple[str, str]]]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    few_shot_df = few_shot_df[few_shot_df[\"lp\"] == lp]\n",
    "\n",
    "    idxs = [rng.choice(few_shot_df.index, size=k, replace=False) for _ in range(n)]\n",
    "    rows = [few_shot_df.loc[idx] for idx in idxs]\n",
    "    examples = [\n",
    "        [(row[\"input\"], row[\"output\"]) for _, row in r.iterrows()]\n",
    "        for r in rows\n",
    "    ]\n",
    "    return examples\n",
    "\n",
    "def write_escaped_lines(lines, path):\n",
    "    lines = [line.replace(\"\\n\", \"\\\\n\") for line in lines]\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(root_dir: Path, lps: List[str]):\n",
    "    train_eval_dfs = {lp: load_train_eval(root_dir, lp) for lp in lps}\n",
    "    few_shot_dfs = {lp: load_few_shot(root_dir, lp) for lp in lps}\n",
    "\n",
    "    for lp, train_eval_df in train_eval_dfs.items():\n",
    "        few_shot_df = few_shot_dfs[lp]\n",
    "        few_shot_examples = sample_examples(few_shot_df, lp=lp, n=len(train_eval_df), k=5)\n",
    "        train_eval_df[\"few_shot_examples\"] = few_shot_examples\n",
    "        train_eval_df[\"zero_shot_instruction\"] = train_eval_df.apply(\n",
    "            lambda x: instruction_template(lp, x[\"input\"]), axis=1,\n",
    "        )\n",
    "        train_eval_df[\"few_shot_instruction1\"] = train_eval_df.apply(\n",
    "            lambda x: format1_few_shot_instruction_template(lp, x[\"input\"], x[\"few_shot_examples\"]), axis=1,\n",
    "        )\n",
    "        train_eval_df[\"few_shot_instruction2\"] = train_eval_df.apply(\n",
    "            lambda x: format2_few_shot_instruction_template(lp, x[\"input\"], x[\"few_shot_examples\"]), axis=1,\n",
    "        )\n",
    "        train_eval_df[\"few_shot_instruction3\"] = train_eval_df.apply(\n",
    "            lambda x: format3_few_shot_instruction_template(lp, x[\"input\"], x[\"few_shot_examples\"]), axis=1,\n",
    "        )\n",
    "        zero_shot_path = root_dir / lp / f\"zero_shot_instructions.txt\"\n",
    "        few_shot1_path = root_dir / lp / f\"few_shot_instructions1.txt\"\n",
    "        few_shot2_path = root_dir / lp / f\"few_shot_instructions2.txt\"\n",
    "        few_shot3_path = root_dir / lp / f\"few_shot_instructions3.txt\"\n",
    "        write_escaped_lines(train_eval_df[\"zero_shot_instruction\"].tolist(), zero_shot_path)\n",
    "        write_escaped_lines(train_eval_df[\"few_shot_instruction1\"].tolist(), few_shot1_path)\n",
    "        write_escaped_lines(train_eval_df[\"few_shot_instruction2\"].tolist(), few_shot2_path)\n",
    "        write_escaped_lines(train_eval_df[\"few_shot_instruction3\"].tolist(), few_shot3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"flores\": {\n",
    "        \"root_dir\": Path(f\"{root_data_dir}/flores/\"),\n",
    "        \"lps\": [\"de-en\", \"en-de\", \"fr-en\", \"en-fr\", \"nl-en\", \"en-nl\", \"pt-en\", \"en-pt\", \"ru-en\", \"en-ru\", \"zh-en\", \"en-zh\"],\n",
    "    },\n",
    "    \"wmt\": {\n",
    "        \"root_dir\": Path(f\"{root_data_dir}/wmt/\"),\n",
    "        \"lps\": [\"de-en\", \"en-de\", \"ru-en\", \"en-ru\", \"zh-en\", \"en-zh\"],\n",
    "    },\n",
    "\n",
    "    \"law\": {\n",
    "        \"root_dir\": Path(f\"{root_data_dir}/law/\"),\n",
    "        \"lps\": [\"de-en\", \"en-de\"],\n",
    "    },\n",
    "    \"medical\": {\n",
    "        \"root_dir\": Path(f\"{root_data_dir}/medical/\"),\n",
    "        \"lps\": [\"de-en\", \"en-de\"],\n",
    "    },\n",
    "\n",
    "    \"tico\": {\n",
    "        \"root_dir\": Path(f\"{root_data_dir}/tico/\"),\n",
    "        \"lps\": [\"en-fr\", \"en-pt\"],\n",
    "    },\n",
    "\n",
    "    \"chat_wmt\": {\n",
    "        \"root_dir\": Path(f\"{root_data_dir}/chat_wmt/\"),\n",
    "        \"lps\": [\"en-de\", \"en-fr\", \"en-pt\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "for dataset, args in tqdm(datasets.items(), total=len(datasets)):\n",
    "    process_dataset(**args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
