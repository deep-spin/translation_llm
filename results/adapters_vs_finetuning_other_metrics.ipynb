{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "\n",
    "params = {\n",
    "    'axes.grid' : True,\n",
    "    \"grid.linestyle\": '--',\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": \"Times New Roman\",\n",
    "}\n",
    "\n",
    "sns.set_style(\"ticks\", params)\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_root_path = Path(\"<path to 7B pretrained flores results>\")\n",
    "best_adapters_root_path = Path(\"<path to 7B best adapters model flores results>\")\n",
    "finetune_root_path = Path(\"<path to 7B best finetuned model flores results>\")\n",
    "\n",
    "def load_scores(scores_file: Path):\n",
    "    lines = scores_file.read_text().splitlines()\n",
    "    scores = {}\n",
    "    for line in lines:\n",
    "        key, value = line.split(\": \")\n",
    "        scores[key] = float(value)\n",
    "    return scores\n",
    "\n",
    "def load_lp(data_root: Path, lp: str, instructions, ckpt: str):\n",
    "    sys_scores_path = data_root / lp / ckpt / instructions / \"sys_scores.txt\"\n",
    "    scores = load_scores(sys_scores_path)\n",
    "    return {\"lp\": lp, **scores}\n",
    "\n",
    "\n",
    "def load_results(data_root: Path, instructions, ckpt: str):\n",
    "    results = []\n",
    "    lps_dirs = [d for d in data_root.iterdir() if d.is_dir()]\n",
    "    for lp_dir in lps_dirs:\n",
    "        lp = lp_dir.name\n",
    "        results.append(load_lp(data_root, lp, instructions, ckpt))\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "pretrained_zero_shot_results = load_results(pretrained_root_path, \"zero_shot_instructions\", \"0\")\n",
    "pretrained_zero_shot_results[\"Model\"] = \"Pretrained\"\n",
    "pretrained_zero_shot_results[\"Context\"] = \"Zero-Shot\"\n",
    "pretrained_few_shot_results = load_results(pretrained_root_path, \"few_shot_instructions2\", \"0\")\n",
    "pretrained_few_shot_results[\"Model\"] = \"Pretrained\"\n",
    "pretrained_few_shot_results[\"Context\"] = \"Five-Shot\"\n",
    "finetune_results = load_results(finetune_root_path, \"zero_shot_instructions\", \"240000\")\n",
    "finetune_results[\"Model\"] = \"Finetuned\"\n",
    "finetune_results[\"Context\"] = \"Zero-Shot\"\n",
    "best_adapters_results = load_results(best_adapters_root_path, \"zero_shot_instructions\", \"20000\")\n",
    "best_adapters_results[\"Model\"] = \"LoRA\"\n",
    "best_adapters_results[\"Context\"] = \"Zero-Shot\"\n",
    "results = pd.concat([pretrained_zero_shot_results, pretrained_few_shot_results, finetune_results, best_adapters_results])\n",
    "results.rename(columns={\"lp\": \"Language Pair\" }, inplace=True)\n",
    "results[\"COMET-22\"] = results[\"COMET-22\"] * 100\n",
    "results[\"COMETKiwi\"] = results[\"COMETKiwi\"] * 100\n",
    "\n",
    "non_eng_lang_order = [\"de\", \"fr\", \"nl\", \"pt\", \"ru\", \"zh\"]\n",
    "lang_pairs = list(chain.from_iterable([[f\"{lang}-en\", f\"en-{lang}\"] for lang in non_eng_lang_order]))\n",
    "models_order = [\"Pretrained\", \"Finetuned\", \"LoRA\"]\n",
    "context_order = [\"Zero-Shot\", \"Five-Shot\"]\n",
    "\n",
    "_, axes = plt.subplots(1, 3, figsize=(14, 3.5))\n",
    "metrics = [\"COMETKiwi\", \"BLEU\", \"chrF\"]\n",
    "metrics2ylabel = {\n",
    "    \"COMET-22\": \"COMET\",\n",
    "    \"COMETKiwi\": \"COMETKiwi\",\n",
    "    \"BLEU\": \"BLEU\",\n",
    "    \"chrF\": \"chrF\",\n",
    "}\n",
    "metrics2ylim = {\n",
    "    \"COMET-22\": (60, 90),\n",
    "    \"COMETKiwi\": (60, 90),\n",
    "    \"BLEU\": (0, 50),\n",
    "    \"chrF\": (0, 80),\n",
    "}\n",
    "# Dont show pretrained zero-shot in the plot as it is poor\n",
    "plot_results = results[~((results[\"Model\"] == \"Pretrained\") & (results[\"Context\"] == \"Zero-Shot\"))].copy()\n",
    "\n",
    "for i, (m, ax) in enumerate(zip(metrics, axes.flatten())):\n",
    "    plot_legend = i == 0\n",
    "    g = sns.barplot(\n",
    "        data=plot_results, x=\"Language Pair\", y=m, hue=\"Model\",\n",
    "        order=lang_pairs,\n",
    "        #order=[\"En-XX\", \"XX-En\"],\n",
    "        hue_order=models_order,\n",
    "        ax=ax,\n",
    "    )\n",
    "    if plot_legend:\n",
    "        g.legend().set_title(\"\")\n",
    "    else:\n",
    "        g.get_legend().remove()\n",
    "    g.set_title(metrics2ylabel[m])\n",
    "    g.set_ylabel(\"\")\n",
    "    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "    g.set_ylim(metrics2ylim[m])\n",
    "    if plot_legend:\n",
    "        sns.move_legend(\n",
    "            g, \"lower center\",\n",
    "            bbox_to_anchor=(1.72, -.5), ncol=3, title=None, frameon=True,\n",
    "        )\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "#plt.savefig(\"figures/adapters_vs_finetuning_other_metrics.pdf\", bbox_inches=\"tight\", dpi=200)\n",
    "\n",
    "def sort_func(x):\n",
    "    if x in lang_pairs:\n",
    "        return lang_pairs.index(x)\n",
    "    elif x in models_order:\n",
    "        return models_order.index(x)\n",
    "    elif x in context_order:\n",
    "        return context_order.index(x)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown value {x}\")\n",
    "\n",
    "results.sort_values(by=[\"Language Pair\", \"Model\", \"Context\"], inplace=True, key=lambda x: x.apply(sort_func))\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "results = results[[\"Language Pair\", \"Model\", \"Context\", \"COMET-22\", \"COMETKiwi\", \"BLEU\", \"chrF\"]]\n",
    "results.rename(columns={\"COMET-22\": \"COMET\"}, inplace=True)\n",
    "results.set_index([\"Language Pair\", \"Model\", \"Context\"], inplace=True)\n",
    "results.to_latex(\"tables/adapters_vs_finetuning.tex\", float_format=\"%.2f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
